# ProfileScope

ProfileScope is the most comprehensive AI-powered social media intelligence platform, providing advanced analysis across 10+ major social platforms including Twitter/X, Instagram, LinkedIn, TikTok, Facebook, YouTube, Snapchat, Pinterest, Reddit, and GitHub. Using cutting-edge machine learning, universal data collection, and real-time processing, ProfileScope delivers immediate insights into profile authenticity, engagement patterns, content analysis, and predictive analytics.

**üöÄ Transformational Platform**: Industry-leading coverage with 333% more platforms than competitors, real-time processing infrastructure, mobile-first design, and complete enterprise features including team collaboration and white-labeling.

## Features

### üåç Universal Platform Coverage
- **10+ Major Platforms**: Twitter/X, Instagram, LinkedIn, TikTok, Facebook, YouTube, Snapchat, Pinterest, Reddit, GitHub
- **Universal Data Collection**: Single API integration via ScrapeCreators
- **Real-time Processing**: Celery + Redis distributed task processing
- **Comprehensive Analysis**: Profile data, content analysis, engagement metrics across all platforms

### ü§ñ Advanced AI Intelligence  
- **Universal AI Access**: OpenRouter integration (GPT-4, Claude-3, Gemini, Llama-2)
- **Multi-dimensional Analysis**: Content, authenticity, personality, predictions
- **Computer Vision**: OpenCV-powered image analysis and authenticity detection
- **Specialized Models**: Platform-specific analysis optimization

### üì± Multi-Interface Access
- **Web Application**: React + TypeScript with responsive design
- **Mobile Apps**: React Native + Expo (iOS/Android)
- **Desktop Application**: PyQt5 native desktop interface
- **API Access**: RESTful API with comprehensive documentation

### üè¢ Enterprise Features
- **Team Collaboration**: Role-based access control (Owner/Admin/Analyst/Viewer)
- **White-label Solution**: Custom branding, domains, and styling
- **Multi-tenancy**: Secure team workspaces and data isolation
- **Usage Analytics**: Comprehensive reporting and insights

### üí∞ Monetization Platform
- **4-Tier Pricing**: Free, Basic, Professional, Enterprise
- **Usage-based Billing**: Transparent cost calculation and tracking
- **Automated Invoicing**: Stripe-compatible payment processing
- **Revenue Analytics**: Business intelligence and usage reporting

### ‚ö° Real-time Processing
- **Background Tasks**: Celery worker queues for scalable processing
- **Live Updates**: WebSocket connections for real-time progress
- **Monitoring**: Flower dashboard for task management
- **Auto-scaling**: Dynamic worker allocation based on demand

## Installation

1. Clone the repository:
```bash
git clone https://github.com/fxinfo24/ProfileScope.git
cd ProfileScope
```

2. Create a virtual environment and activate it:
```bash
python -m venv venv
source venv/bin/activate  # On Windows use: venv\Scripts\activate
```

3. Install dependencies:

**Requirements Files:**
- `requirements.txt` - Ultra-minimal for Railway/production (fast build, ~1-2 min)
- `requirements-railway-medium.txt` - Medium build with some NLP features
- `requirements-full.txt` - Complete local development environment with ML/AI

```bash
# Local development (recommended):
pip install -r requirements-full.txt

# Railway will auto-detect requirements.txt (minimal, fast builds)
```

4. Setup NLP components:
```bash
# Download NLTK data
python -c "import nltk; nltk.download('punkt'); nltk.download('stopwords'); nltk.download('vader_lexicon')"
```

5. Configure API credentials:
- Copy `.env.example` to `.env`
- Fill in your Twitter/Facebook API credentials
- See `docs/setup_guide.md` for detailed setup instructions

## Usage

### Command Line Interface

Analyze a profile:
```bash
# Main launcher (this repo uses bin/run.py)
python3 bin/run.py --web
# or
python3 bin/run.py --desktop
```

Options (launcher):
- `--web`: run the Flask web app
- `--desktop`: run the desktop app
- `--host`, `--port`, `--debug`: web server options

### Real-time Processing
Start the Celery workers for background processing:
```bash
# Start real-time processing pipeline
scripts/start_celery.sh

# Monitor tasks at http://localhost:5555 (Flower dashboard)
```

### Mobile Application
Build and run mobile apps:
```bash
cd mobile
npm install
npx expo start

# For iOS: npx expo start --ios
# For Android: npx expo start --android
```

### Desktop Application

Launch the desktop GUI:
```bash
python -m app.desktop.app
```

### Web Interface

Start the web server:
```bash
python3 bin/run.py --web
```

### Database migrations (production)

This repo includes Alembic/Flask-Migrate in `migrations/`.

- In development/testing, the app may use `db.create_all()`.
- In production (Railway/Postgres), run migrations instead (e.g., as a Railway **Release Command**):

```bash
export DATABASE_URI="postgresql://..."
export FLASK_APP=app.web.app
flask db upgrade
```

## Production Deployment

### Complete Railway + Vercel Deployment Guide

#### Prerequisites
- GitHub repository connected to Railway
- Vercel account connected to GitHub
- Railway project with Postgres and Redis add-ons

#### Step 1: Railway Backend Setup

**1.1 Create Web Service**
```bash
# Railway auto-detects Procfile and runs "web" command
# Command: gunicorn -b 0.0.0.0:$PORT app.web.app:create_app()
```

**1.2 Add Database Services**
- Click "New" ‚Üí "Database" ‚Üí "Add PostgreSQL"
- Click "New" ‚Üí "Database" ‚Üí "Add Redis"
- Railway automatically sets `DATABASE_URI` and `REDIS_URL`

**1.3 Configure Environment Variables**
```bash
# Required
SECRET_KEY=your-secure-random-key-here
CORS_ORIGINS=https://your-frontend.vercel.app,https://yourdomain.com

# Optional API Keys
SCRAPECREATORS_API_KEY=your_api_key
OPENROUTER_API_KEY=your_api_key
```

**1.4 Enable Database Migrations**
Set Railway release command:
```bash
flask db upgrade
```

**1.5 Deploy Worker Service (Optional - for async tasks)**
- Create NEW Railway service from SAME GitHub repo
- Set custom start command:
  ```bash
  celery -A app.core.tasks worker --pool=solo --loglevel=info --queues=analysis
  ```
- Ensure `REDIS_URL` and `DATABASE_URI` are available
- Deploy alongside web service

**Important**: 
- Uses `--pool=solo` to avoid mmap dependency issues in containerized environments
  - Railway's Nixpacks Python build may be missing the `mmap` module required for multiprocessing
  - Solo pool runs single-threaded (1 task at a time) but uses less memory and works reliably
  - Sufficient for ProfileScope's I/O-bound tasks (~120-180 tasks/hour)
  - Scale horizontally by adding more worker services if higher throughput is needed
- Without Redis/Worker, the app uses threading fallback (works fine for moderate load)

#### Step 2: Vercel Frontend Setup

**2.1 Connect Repository**
- Import your GitHub repository to Vercel
- Framework preset: Vite
- Root directory: `frontend`

**2.2 Configure Build Settings**
```bash
Build command: npm run build
Output directory: dist
Install command: npm install
```

**2.3 Set Environment Variables**
```bash
VITE_API_BASE_URL=https://your-service.up.railway.app/api
```

**2.4 Deploy**
- Vercel auto-deploys on push to main
- Preview deployments for pull requests

#### Step 3: Verify Deployment

**3.1 Test CORS**
```bash
curl -I https://your-service.up.railway.app/api/stats/completion-rate \
  -H "Origin: https://your-frontend.vercel.app"
# Should return: Access-Control-Allow-Origin header
```

**3.2 Test API Endpoints**
```bash
# Health check
curl https://your-service.up.railway.app/api/tasks

# Create analysis
curl -X POST https://your-service.up.railway.app/api/analyze \
  -H "Content-Type: application/json" \
  -d '{"platform":"twitter","profile_id":"test"}'
```

**3.3 Monitor Services**
- Railway: Check deployment logs and metrics
- Vercel: Monitor function invocations
- Database: Monitor connection pool usage

#### Troubleshooting

**CORS Issues**
- Verify `CORS_ORIGINS` matches your Vercel URL exactly
- Check browser console for specific error messages
- Ensure no trailing slashes in URLs

**Database Connection**
- Railway Postgres auto-configures `DATABASE_URI`
- Run migrations: `flask db upgrade`
- Check connection pool settings

**Worker Not Processing**
- Verify Redis is running and `REDIS_URL` is set
- Check worker service logs in Railway
- If worker crashes with "ModuleNotFoundError: No module named 'mmap'":
  - Ensure you're using `--pool=solo` flag in the worker start command
  - Railway's Python may lack the mmap module needed for prefork multiprocessing
  - Solo pool is the recommended solution for containerized environments
- Without worker, tasks run via threading (acceptable for low/medium load)

For detailed setup instructions, see `docs/setup_guide.md`.

### Results storage (production)

- Task results are persisted in the database in `task.result_data` (Postgres JSONB).
- The `task.result_data` column is **deferred** by default to keep task listing fast.
- `/api/tasks/<id>/results` and `/api/tasks/<id>/download` serve results from the DB.
### Shortcut for Both

```bash
python3 bin/run.py --desktop  # Desktop app
python3 bin/run.py --web      # Web interface
```

Access the web interface at `http://localhost:5000`

## Development

### Project Structure

- `app/core/`: Core analysis engine with universal API integration
- `app/desktop/`: Desktop GUI application (PyQt5)
- `app/web/`: Web application (Flask + React TypeScript frontend)
- `app/enterprise/`: Team management and white-label features
- `app/utils/`: Utility functions and helpers
- `frontend/`: React + TypeScript web interface
- `mobile/`: React Native + Expo mobile applications
- `tests/`: Comprehensive test suites
- `data/`: Data storage and results
- `docs/`: Complete documentation including transformational achievements
- `scripts/`: Deployment and management scripts

### Running Tests

Run tests inside the project virtualenv after installing dependencies:

```bash
python3 bin/run_tests.py --simple
python3 bin/run_tests.py
# or
python -m pytest
```

### Contributing

1. Fork the repository
2. Create a feature branch
3. Make your changes
4. Run tests
5. Submit a pull request

## License

This project is licensed under the MIT License - see the LICENSE file for details.

## Acknowledgments

- Thanks to all contributors
- Built with Python and modern data analysis libraries
- Powered by machine learning and NLP technologies

## Documentation

### Complete Documentation
- **Setup Guide**: `docs/setup_guide.md` - Comprehensive installation and configuration
- **API Documentation**: `docs/api.md` - Complete REST API reference
- **Development Guide**: `docs/development.md` - Developer setup and contribution guide  
- **Desktop & Mobile**: `docs/desktop.md` - Desktop and mobile application documentation
- **üöÄ Implementation Progress**: `docs/IMPLEMENTATION_TRACKER.md` - Platform achievements and development progress
- **Implementation Tracker**: `docs/IMPLEMENTATION_TRACKER.md` - Development progress and milestones

## Achievements Summary

üåç **10+ Platform Coverage** - More comprehensive than any competitor  
‚ö° **Real-time Processing** - 10x faster than traditional batch processing  
ü§ñ **Universal AI Integration** - Access to GPT-4, Claude-3, Gemini, Llama-2  
üì± **Mobile-First Design** - Cross-platform iOS and Android apps  
üè¢ **Enterprise Ready** - Team collaboration and white-label solutions  
üí∞ **Complete Monetization** - Usage-based billing and revenue analytics  

**Result**: Industry-leading social media intelligence platform ready for commercial deployment.

## Support

For support, please:
1. Check the comprehensive documentation in the `docs/` directory
2. Review the transformational achievements document for platform capabilities
3. Open an issue on GitHub with detailed information
4. Contact the development team for enterprise inquiries
